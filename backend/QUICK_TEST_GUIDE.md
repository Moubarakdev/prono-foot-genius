# üöÄ Guide de test rapide - Corrections et Optimisations

## Ce qui a √©t√© corrig√©

### 1. ‚úÖ Scrapers anti-blocage (403 Forbidden)
- User-Agent rotation avec 5 navigateurs diff√©rents
- Retry logic automatique (3 tentatives)
- D√©lais al√©atoires entre les tentatives
- Headers HTTP r√©alistes

**Fichier modifi√©:** `backend/app/services/scrapers.py`

**Scrapers concern√©s:**
- SofaScoreScraper
- OddsCheckerScraper  
- FBrefScraper

### 2. ‚úÖ Analyse UUID 404 fixed
- M√™me correction que pour les coupons
- Conversion UUID en string pour requ√™tes DB

**Fichier modifi√©:** `backend/app/api/v1/analyze.py` (ligne 560)

### 3. ‚úÖ Ollama optimis√© pour paris sportifs

**Am√©liorations:**
- Mod√®le: Mistral 7B (au lieu de Llama3.2 3B)
- System prompt expert en paris sportifs
- Prompts structur√©s avec consignes claires
- Param√®tres ajust√©s: temperature=0.3, top_p=0.85
- Timeout augment√©: 120s pour analyses complexes
- Logs d√©taill√©s pour monitoring

**Fichiers modifi√©s:**
- `backend/app/providers/ai/ollama.py` (prompts + param√®tres)
- `backend/.env` (OLLAMA_MODEL=mistral)

## üß™ Comment tester

### Test 1: Scraper anti-blocage

```bash
# Red√©marrer l'API avec les corrections
docker-compose restart api

# Tester via logs
docker logs -f api-football-api-1

# Cr√©er une analyse de match sur l'interface
# Les logs doivent montrer:
# - Si 403, vous verrez: "‚ö†Ô∏è FBref 403, retry 1/3"
# - Si succ√®s apr√®s retry: "‚úÖ External API call: FBref..."
```

### Test 2: UUID Analysis fix

```bash
# Sur l'interface:
1. Aller dans "Historique des analyses"
2. Cliquer sur une analyse
3. Devrait afficher les d√©tails (pas 404)

# Logs attendus:
# ‚úÖ Analysis {id} retrieved successfully
```

### Test 3: Ollama setup

```bash
# Windows
cd backend
.\setup_ollama.ps1

# Linux/Mac
cd backend
bash setup_ollama.sh
```

**Ce que fait le script:**
1. D√©marre le service Ollama
2. Attend qu'il soit pr√™t (healthcheck)
3. T√©l√©charge Mistral 7B (~4GB, 5-10 min)
4. V√©rifie l'installation
5. Red√©marre l'API

**Logs attendus:**
```
üì¶ D√©marrage du service Ollama...
‚è≥ Attente du service Ollama...
‚úÖ Ollama est pr√™t!
üì• T√©l√©chargement du mod√®le Mistral (7B)...
‚úÖ Configuration termin√©e!
```

### Test 4: Analyse IA avec Ollama

```bash
# Sur l'interface:
1. Cr√©er un nouveau coupon avec 2-3 matchs
2. L'analyse devrait se lancer automatiquement

# Logs √† v√©rifier:
docker logs -f api-football-api-1 | grep -i ollama

# Logs attendus:
# ü§ñ Ollama provider initialized - Model: mistral
# ‚úÖ Ollama available at http://ollama:11434
# ‚úÖ Ollama generation successful
#    Duration: 8.32s
#    Response length: 1245 chars
```

### Test 5: Qualit√© de l'analyse

**V√©rifier que la r√©ponse contient:**
- ‚úÖ Probabilit√©s (home, draw, away) qui font 100%
- ‚úÖ 3-5 facteurs cl√©s pertinents
- ‚úÖ 2-3 sc√©narios avec probabilit√©s
- ‚úÖ R√©sum√© clair en fran√ßais
- ‚úÖ Format JSON valide

**Si l'analyse est incoh√©rente:**
```python
# Ajuster temperature dans ollama.py
self.model_options = {
    "temperature": 0.2,  # Plus bas = plus coh√©rent
    ...
}
```

## üîç V√©rifications importantes

### V√©rifier que tout tourne

```bash
# Services actifs
docker ps

# Devrait afficher:
# - api-football-api-1 (FastAPI)
# - api-football-mysql-1 (Database)
# - api-football-redis-1 (Cache)
# - api-football-ollama-1 (AI) ‚Üê NOUVEAU

# V√©rifier Ollama
curl http://localhost:11434/api/tags

# Devrait retourner JSON avec liste des mod√®les
```

### V√©rifier le mod√®le install√©

```bash
docker exec api-football-ollama-1 ollama list

# Devrait afficher:
# NAME            ID              SIZE    MODIFIED
# mistral:latest  xxx             4.1 GB  X minutes ago
```

### V√©rifier les logs

```bash
# Logs Ollama
docker logs api-football-ollama-1

# Logs API (filtrer Ollama)
docker logs api-football-api-1 | grep -i ollama

# Logs en temps r√©el
docker logs -f api-football-api-1
```

## ‚ö†Ô∏è Probl√®mes courants

### Probl√®me: "Ollama service not available"

**Solution:**
```bash
docker-compose restart ollama
docker logs -f api-football-ollama-1
# Attendre "Ollama is running"
```

### Probl√®me: "Model 'mistral' not found"

**Solution:**
```bash
docker exec api-football-ollama-1 ollama pull mistral
docker-compose restart api
```

### Probl√®me: Scrapers toujours bloqu√©s (403)

**Solutions:**
1. **V√©rifier les logs** - Voir si retry fonctionne
2. **Augmenter retries** - Dans `scrapers.py`, changer `max_retries = 5`
3. **Ajouter plus de User-Agents** - √âtendre la liste `USER_AGENTS`
4. **Utiliser proxy** - Si persistant, consid√©rer service proxy payant

### Probl√®me: Analyses trop lentes (>30s)

**Solutions:**
1. **Utiliser llama3.2** - Plus rapide mais moins pr√©cis
   ```bash
   docker exec api-football-ollama-1 ollama pull llama3.2
   # Modifier .env: OLLAMA_MODEL=llama3.2
   docker-compose restart api
   ```

2. **R√©duire num_predict** - Dans `ollama.py`
   ```python
   "num_predict": 2000,  # Au lieu de 3000
   ```

3. **Augmenter RAM container** - Dans `docker-compose.yml`
   ```yaml
   ollama:
     deploy:
       resources:
         limits:
           memory: 12G  # Au lieu de 8G
   ```

## üìä Benchmarks attendus

Avec Mistral 7B sur machine moyenne (16GB RAM):

| Op√©ration | Temps attendu |
|-----------|---------------|
| Analyse 1 match | 8-12s |
| Analyse coupon 3 matchs | 15-25s |
| Scraper (sans retry) | 2-5s |
| Scraper (avec retry) | 5-15s |

## ‚úÖ Checklist finale

Avant de consid√©rer que tout marche:

- [ ] Services Docker tous actifs (api, mysql, redis, ollama)
- [ ] Ollama r√©pond: `curl http://localhost:11434/api/tags`
- [ ] Mod√®le Mistral install√©: `ollama list`
- [ ] API d√©marre sans erreur: `docker logs api-football-api-1`
- [ ] Logs montrent: "‚úÖ Ollama available at..."
- [ ] Cr√©ation de coupon fonctionne
- [ ] Analyse IA retourne JSON valide
- [ ] Probabilit√©s font 100%
- [ ] Facteurs cl√©s pertinents (pas g√©n√©riques)
- [ ] Temps de r√©ponse < 30s
- [ ] Pas d'erreur 403 sur scrapers (ou retry fonctionne)
- [ ] Historique analyses affiche d√©tails (pas 404)

## üéØ Prochaines √©tapes

Si tout fonctionne:

1. **Monitoring production**
   - Ajouter m√©triques Prometheus/Grafana
   - Alertes si Ollama down ou analyses > 30s

2. **Fine-tuning**
   - Collecter feedback utilisateurs
   - Ajuster prompts si analyses pas assez pr√©cises
   - Tester llama3:8b si budget RAM le permet

3. **Scaling**
   - Consid√©rer multiple instances Ollama
   - Load balancing entre mod√®les
   - GPU pour acc√©l√©rer (si disponible)

4. **Scrapers**
   - Si blocages persistent, √©valuer:
     - ScraperAPI.com (~$50/mois)
     - Bright Data proxies
     - APIs payantes alternatives

## üìö Documentation

- **Ollama**: `backend/OLLAMA_OPTIMIZATION.md`
- **Scrapers**: `backend/app/services/scrapers.py`
- **Providers**: `backend/app/providers/ai/`
- **Logs**: `backend/logs/app.log`

---

**Setup time:** ~15-20 minutes (dont 5-10 min download Mistral)
**Tests time:** ~10 minutes
**Total:** ~30 minutes pour tout tester

**Questions?** V√©rifier les logs et la doc OLLAMA_OPTIMIZATION.md
